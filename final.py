# reference :http://scikit-image.org/docs/dev/auto_examples/plot_hog.html

data_root = '/home/spuran/Caffe/caffe/data/Images/'# give the root directory where test and train image folders are present

import os
import numpy as np
from skimage.feature import hog
from skimage.transform import resize
from skimage import io, data, color
import pandas as pd

train_photos = pd.read_csv('/home/spuran/ML_FINAL_PROJECT/new_train11.csv')#this the same csv fiel generated while by read_me.py
train_folder = data_root+'train/'
train_images_path = [os.path.join(train_folder, str(x)+'.jpg') for x in train_photos['id']]  # get full filename
num_train = len(train_images_path)
#some images which had error have been deleted along with their corresponding lables
#these images were identiifed while converting them to lmdb format itself for my initial trial with caffe
print "Number of training images: ", num_train
list_features =[] # to store the features returned by hog method (ref::http://scikit-image.org/docs/dev/auto_examples/plot_hog.html)


for i in range(0, num_train):

    image = io.imread(train_images_path[i])#reads  each image from the path list
    image = color.rgb2gray(image)#converts them from color to gray
    image_resized = resize(image, (224, 224))# every image is resized to 224X224
    feature = hog(image_resized, orientations=8,
                  pixels_per_cell=(16, 16), cells_per_block=(1, 1))
    list_features.append(feature)#appended to a list
print len(list_features) ,"length of list features"
feature_array = np.asarray(list_features)# converting the list to an ndarray
X_train = feature_array#storing it as X_train
print feature_array.shape,"shape of feature array"


list1 =[]#for storing the labels
i =0
path = '/home/spuran/ML_FINAL_PROJECT/new_train11.csv'#path of the csv file generated while running read_train.py
with open(path,'r') as csvfile:
    data = csvfile.readlines()
    for line in data:
        array = line.split(",")
        if array[1] != "label":
            if i == 0:
                junk = array[1]

            else:
                str_label= array[1]
                str_label = str_label[1:-3]
                int_label = int(str_label)
                # print str_label
                # print type(array[1])
                list1.append([(int_label)])
        i+=1


labels = np.asarray(list1)#converting them as ndarray
print len(labels),"length of labels"
y_train = labels

#(--------------------------------------------------------------------------------------------------------------)
#preparing dest data
test_photos = pd.read_csv(data_root+'test.csv',delim_whitespace=True)#path of the csv generated by running test_name.py
test_folder = data_root+'test/'
test_images = [os.path.join(test_folder, str(x)+'.jpg') for x in test_photos['id']]#get the path of the file with their id being read from test_photos
num_test = len(test_images)
print "Number of test images: ", num_test
list_features_test = []
error_list =[]
for i in range(0, num_test):
    try:
        image = io.imread(test_images[i])#processing each image and converting it to grey and resizing befoe extracting hog features
        image = color.rgb2gray(image)
        image_resized = resize(image, (224, 224))
        feature = hog(image_resized, orientations=8,
                      pixels_per_cell=(16, 16), cells_per_block=(1, 1))
        list_features_test.append(feature)
    except(NameError,ValueError,IOError,MemoryError):
        print "there is an error"
        error_list.append(test_images[i])#there are two miscalssified images so the paths of these will be here
        continue

feature_array_test = np.asarray(list_features_test)#converting the list to an ndarray
X_test = feature_array_test
print feature_array_test.shape

from sklearn.cross_validation import train_test_split
from sklearn.multiclass import OneVsRestClassifier
import time
t=time.time()

#Convert list of labels to binary matrix

random_state = np.random.RandomState(0)
X_ptrain, X_ptest, y_ptrain, y_ptest = train_test_split(X_train, y_train, test_size=.2,random_state=random_state)#splitting the data for cross validation (80-20)

print "Time passed: ", "{0:.1f}".format(time.time()-t), "sec"

from sklearn.linear_model import LogisticRegression
OVR = OneVsRestClassifier(LogisticRegression())#using logistic regression for classsifciation
OVR.fit(X_ptrain, y_ptrain)
print "accuracy", OVR.score(X_ptest,y_ptest)#checking the accuracy
from sklearn.metrics import log_loss#for checing the log loss
Y1_final =OVR.predict_proba(X_ptest)
print (Y1_final[0])
print log_loss(y_ptest,Y1_final)#log loss value
test_ids = [[str(x)] for x in test_photos['id']]#getting the test ids for writing the final submission
print type(test_ids)
a = np.asarray(test_ids)
print type(a),a.shape,a[1]

import csv



np.savetxt("submisoon1.csv",Y1_final.astype(dtype = float),delimiter =",",fmt = '%1.5f')#stores only the posteriror probabiltites into 8 columns for each image
with open(data_root+"submission_label.csv",'w') as wr:#writes only the ids into a csv file and the we have to merge both the files manually
                                                    #this is done as hen wriing them both together was causing sudden jumps
                                                    #  in some columns so i adjusted it this way
        wr = csv.writer(wr, quoting=csv.QUOTE_ALL)

        for id in a :
                wr.writerow(id)



print error_list




